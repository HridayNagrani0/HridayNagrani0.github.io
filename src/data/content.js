export const portfolioData = {
    personalInfo: {
      name: "Your Name",
      title: "Robotics & AI Engineer",
      subtitle: "Specializing in Computer Vision, NLP, and Extended Reality",
      email: "email@example.com",
      github: "https://github.com/yourusername",
      linkedin: "https://linkedin.com/in/yourusername"
    },
    
    featuredProjects: [
      {
        id: 1,
        title: "Project Title",
        description: "Brief project description",
        technologies: ["React", "Python", "TensorFlow"],
        image: "/placeholder.jpg",
        demoLink: "https://demo.com",
        githubLink: "https://github.com/project",
        highlights: ["Key achievement 1", "Key achievement 2"]
      }
      // Add more projects
    ],
  
    experience: [
      {
        id: 1,
        role: "Research Assistant",
        company: "University/Company Name",
        duration: "Jan 2023 - Present",
        description: "Key responsibilities and achievements",
        technologies: ["Technology 1", "Technology 2"]
      }
      // Add more experiences
    ],
  
    skills: {
      technical: ["Python", "React", "TensorFlow", "Computer Vision"],
      tools: ["Git", "Docker", "VS Code"],
      domains: ["Robotics", "AI", "Extended Reality"]
    },
  
    research: [
      {
        id: 1,
        title: "Research Project Title",
        description: "Brief description",
        publication: "Conference/Journal name",
        link: "https://doi.org/..."
      }
      // Add more research projects
    ],
  
    certifications: [
      {
        id: 1,
        name: "Certification Name",
        issuer: "Issuing Organization",
        date: "2023",
        link: "https://verify.cert"
      }
      // Add more certifications
    ]
  };

export const education = [
  {
    school: "Arizona State University",
    degree: "Master of Science in Robotics and Autonomous Systems (Artificial Intelligence)",
    location: "Tempe, Arizona",
    duration: "Expected May 2025",
    gpa: "4.0/4.0"
  },
  {
    school: "Ahmedabad University",
    degree: "Bachelor of Technology in Information and Communication Technology",
    location: "Ahmedabad, India",
    duration: "August 2018 - May 2022",
    gpa: "3.19/4.0"
  }
];

export const skills = {
  webDevelopment: [
    "Django",
    "Firebase",
    "MongoDB",
    "Redux",
    "React",
    "Adobe XD"
  ],
  programmingAndML: [
    "Python",
    "C",
    "C#",
    "C++",
    "Java",
    "Node.js",
    "Microsoft-tools",
    "Tensorflow",
    "Pytorch",
    "Keras",
    "AWS",
    "Kubernetes",
    "Kafka",
    "Unity"
  ]
};

export const publications = [
  {
    title: "Enhanced Human-Pose Estimation",
    description: "Enhanced human-pose estimation by 43% with SplitGlass implementation using PyTorch",
    link: "#"
  },
  {
    title: "Chest X-ray Segmentation",
    description: "Optimized Chest X-ray segmentation, reducing complexity by 70% with PyTorch",
    link: "#"
  },
  {
    title: "Facial Expressions Recognition",
    description: "99.8% accuracy on CK+ dataset for Facial Expressions Recognition utilizing TensorFlow",
    link: "#"
  }
];

export const experience = [
  {
    company: "Meteor Studio at Arizona State University",
    role: "Extended Reality (XR) Creative Developer",
    location: "AZ, USA",
    duration: "June 2024 - Current",
    technologies: "C#, Unity, Quest3",
    responsibilities: [
      "Developed an advanced AR/VR-based media player for a graduate-level semiconductor metrology course, leading to a 13% improvement in student engagement and understanding, in mid-semester evaluations",
      "Implemented networking and co-location features using Unity Netcode and Meta's Oculus Integration SDK, enabling real-time multi-user interactions and collaborative learning experiences within the XR application"
    ]
  },
  {
    company: "Arizona State University",
    role: "Research Aide: Computer Vision",
    location: "AZ, USA",
    duration: "January 2024 - Current",
    technologies: "Python, Pytorch",
    responsibilities: [
      "Reduced YOLOv8 size by 40% via model pruning and quantization, maintaining performance and enhancing data processing efficiency, leading to 30% deployment cost savings",
      "Collaborated with a talented team to drive a 30% boost in object detection recall for satellite imagery by pioneering the integration of neuro-symbolic techniques with neural networks"
    ]
  },
  {
    company: "Indian Space Research Organization",
    role: "Research Intern",
    location: "Ahmedabad, India",
    duration: "January 2022 - July 2022",
    technologies: "Python, Tensorflow, Pytorch, AWS, Kafka",
    responsibilities: [
      "Attained mAP of 48.0 on PRW dataset and 94.0 on CUHK-SYSU for sequential person search using Torch",
      "Collaborated on designing, coding, and testing computer vision algorithms, leading to a 15% reduction in error rate per frame during video stream processing from CCTV cameras"
    ]
  }
];

export const projects = [
  {
    title: "Tic-Tac-Toe with MyCobot and Yolov8",
    technologies: "Python, Pytorch, MyCobot",
    githubLink: "#",
    description: "Crafted and executed a comprehensive strategy to enhance user experience through real-time game object identification and precise move execution, utilizing advanced algorithms to achieve outstanding accuracy rates exceeding 90%"
  },
  {
    title: "Lightning NeRF Extension with Semantic Information",
    technologies: "Python, Pytorch",
    description: "Lead a team to re-implement the state-of-the-art Lightning NeRF framework, for efficient radiance field reconstruction in autonomous driving scenarios and extended the framework by incorporating semantic information, enabling the model to understand and reason about the scene's components semantically, leading to a 10% improvement in the model's PSNR"
  },
  {
    title: "U-Net for Real-Time Medical Image Segmentation",
    technologies: "Python, Pytorch, JetsonNano",
    description: "Achieved high inference speed (353.28 FPS) and high segmentation accuracy (Dice Score: 0.9602) by adapting and optimizing U-Net architecture using TensorRT, enhancing real-time medical diagnostic capabilities on the Jetson Nano"
  },
  {
    title: "Localization of Lung Nodules Using Deep Learning",
    technologies: "Python, Pytorch",
    description: "Spearheaded the adaptation and implementation of the Co-DETR framework for precise detection and localization of lung nodules in chest X-rays using the NODE21 dataset, achieving an initial Average Precision of 0.6812, significantly enhancing early cancer detection capabilities"
  }
];

export const contact = {
  email: "hnagrani@asu.edu",
  phone: "+1-6237037724",
  linkedin: "#", // Add your LinkedIn URL
  github: "#"    // Add your Github URL
};

export const bio = {
  name: "Hriday Rajesh Nagrani",
  title: "MS in Robotics and Autonomous Systems",
  subtitle: "Specializing in Artificial Intelligence and Computer Vision",
  description: `I am a graduate student at Arizona State University, passionate about pushing the boundaries of AI and Computer Vision. 
  With extensive experience in developing cutting-edge solutions in Extended Reality (XR) and Computer Vision, 
  I focus on creating innovative applications that bridge the gap between theoretical research and practical implementation.
  
  My research interests include Computer Vision, Deep Learning, and Extended Reality, with a particular focus on 
  real-time applications and optimization techniques. I have successfully led multiple projects that demonstrate 
  the practical applications of these technologies in various domains.`,
  highlights: [
    "Expertise in Computer Vision and Deep Learning",
    "Experience in XR Development and Research",
    "Strong background in AI optimization and deployment",
    "Published researcher in pose estimation and medical imaging"
  ]
};